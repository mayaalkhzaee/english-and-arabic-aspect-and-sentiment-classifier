{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf7108fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = \"C:\\\\Users\\\\ahmed\\\\Downloads\\\\aspect_extraction_and_classification\\\\Laptop_Train_v2.xml\"\n",
    "DATA_PATH = \"C:\\\\Users\\\\ahmed\\\\Downloads\\\\aspect_extraction_and_classification\\\\final_dataset.jsonl\"  \n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "WINDOW_SIZE = 5 \n",
    "DROP_CONFLICT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc98cea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '2339', 'text': 'I charge it at night and skip taking the cord with me because of the good battery life.', 'aspects': [{'term': 'cord', 'polarity': 'neutral', 'from': 41, 'to': 45}, {'term': 'battery life', 'polarity': 'positive', 'from': 74, 'to': 86}]}\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def load_semeval_xml(path: str):\n",
    "    \"\"\"\n",
    "    Parse SemEval ABSA XML file into a list of dicts:\n",
    "    {\n",
    "      \"id\": str,\n",
    "      \"text\": str,\n",
    "      \"aspects\": [\n",
    "         {\"term\": str, \"polarity\": str, \"from\": int, \"to\": int},\n",
    "         ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    tree = etree.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for sentence in root.findall(\"sentence\"):\n",
    "        sent_id = sentence.get(\"id\")\n",
    "        text_elem = sentence.find(\"text\")\n",
    "        if text_elem is None:\n",
    "            continue\n",
    "        text = text_elem.text.strip()\n",
    "\n",
    "        aspects = []\n",
    "        aspect_terms = sentence.find(\"aspectTerms\")\n",
    "\n",
    "        if aspect_terms is not None:\n",
    "            for term in aspect_terms.findall(\"aspectTerm\"):\n",
    "                aspects.append({\n",
    "                    \"term\": term.get(\"term\"),\n",
    "                    \"polarity\": term.get(\"polarity\"),\n",
    "                    \"from\": int(term.get(\"from\")),\n",
    "                    \"to\": int(term.get(\"to\")),\n",
    "                })\n",
    "\n",
    "        data.append({\n",
    "            \"id\": sent_id,\n",
    "            \"text\": text,\n",
    "            \"aspects\": aspects,\n",
    "        })\n",
    "\n",
    "    return data\n",
    "\n",
    "print(load_semeval_xml(DATA_PATH)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec2b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'text': 'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^', 'aspects': [{'term': 'sound track', 'polarity': 'positive', 'from': 5, 'to': 16}, {'term': 'music', 'polarity': 'positive', 'from': 128, 'to': 133}, {'term': 'guitars', 'polarity': 'positive', 'from': 314, 'to': 321}, {'term': 'orchestras', 'polarity': 'positive', 'from': 334, 'to': 344}, {'term': 'keyboarding', 'polarity': 'negative', 'from': 266, 'to': 277}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl_aspects(path: str):\n",
    "    \"\"\"\n",
    "    Each line in the JSONL file is a dict:\n",
    "    {\n",
    "      \"id\": int,\n",
    "      \"sentence\": str,\n",
    "      \"aspect_terms\": [\n",
    "          {\"term\": \"...\", \"polarity\": \"...\", \"from\": int, \"to\": int}\n",
    "      ]\n",
    "    }\n",
    "    Returns the same structure as load_semeval_xml().\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            sentence = obj[\"sentence\"]\n",
    "            aspects = []\n",
    "\n",
    "            for asp in obj.get(\"aspect_terms\", []):\n",
    "                aspects.append({\n",
    "                    \"term\": asp[\"term\"],\n",
    "                    \"polarity\": asp[\"polarity\"],\n",
    "                    \"from\": asp[\"from\"],\n",
    "                    \"to\": asp[\"to\"],\n",
    "                })\n",
    "\n",
    "            data.append({\n",
    "                \"id\": obj[\"id\"],\n",
    "                \"text\": sentence,\n",
    "                \"aspects\": aspects\n",
    "            })\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c64d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple English text cleaning:\n",
    "    - lowercasing\n",
    "    - remove HTML-like tags\n",
    "    - normalize whitespace\n",
    "    (You can add more if you want.)\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)         \n",
    "    text = re.sub(r\"\\s+\", \" \", text)            \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e58c3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absa/aspect_windows.py\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def char_to_token_window(text: str, start_char: int, end_char: int, window_size: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Convert char offsets into a token-level window of ±window_size words\n",
    "    around the aspect, and insert <ASP> ... </ASP> markers.\n",
    "    \"\"\"\n",
    "    # tokenization by whitespace\n",
    "    tokens = []\n",
    "    starts = []\n",
    "    for m in re.finditer(r'\\S+', text):\n",
    "        tokens.append(m.group())\n",
    "        starts.append(m.start())\n",
    "\n",
    "    aspect_start_tok = None\n",
    "    aspect_end_tok = None\n",
    "\n",
    "    for i, (tok, s) in enumerate(zip(tokens, starts)):\n",
    "        e = s + len(tok)\n",
    "        # aspect start char falls into this token\n",
    "        if s <= start_char < e and aspect_start_tok is None:\n",
    "            aspect_start_tok = i\n",
    "        # aspect end char falls into this (or previous) token\n",
    "        if s < end_char <= e:\n",
    "            aspect_end_tok = i\n",
    "            break\n",
    "\n",
    "    if aspect_start_tok is None:\n",
    "        # fallback: full sentence if mapping fails\n",
    "        return text\n",
    "\n",
    "    if aspect_end_tok is None:\n",
    "        aspect_end_tok = aspect_start_tok\n",
    "\n",
    "    left = max(0, aspect_start_tok - window_size)\n",
    "    right = min(len(tokens), aspect_end_tok + 1 + window_size)\n",
    "\n",
    "    window_tokens = tokens[left:right]\n",
    "\n",
    "    rel_start = aspect_start_tok - left\n",
    "    rel_end = aspect_end_tok - left\n",
    "\n",
    "    # Insert tags around aspect span\n",
    "    window_tokens.insert(rel_start, \"<ASP>\")\n",
    "    # +2 because inserting opening tag shifts indices\n",
    "    window_tokens.insert(rel_end + 2, \"</ASP>\")\n",
    "\n",
    "    return \" \".join(window_tokens)\n",
    "\n",
    "\n",
    "def build_apc_dataset_with_windows(parsed_xml, window_size: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a DataFrame with columns:\n",
    "      - sentence: original sentence text (cleaned)\n",
    "      - aspect: aspect term (cleaned)\n",
    "      - polarity: label\n",
    "      - window: aspect-centered window with <ASP> tags\n",
    "      - input_full: aspect + [SEP] + full sentence (for comparison)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for item in parsed_xml:\n",
    "        raw_text = item[\"text\"]\n",
    "        text = clean_text(raw_text)\n",
    "\n",
    "        for asp in item[\"aspects\"]:\n",
    "            term = asp[\"term\"]\n",
    "            pol = asp[\"polarity\"]\n",
    "            start = asp[\"from\"]\n",
    "            end = asp[\"to\"]\n",
    "\n",
    "            # Build window using original text (for offsets)\n",
    "            window_raw = char_to_token_window(raw_text, start, end, window_size=window_size)\n",
    "            window = clean_text(window_raw)\n",
    "            aspect_clean = clean_text(term)\n",
    "\n",
    "            input_full = f\"{aspect_clean} [SEP] {text}\"\n",
    "\n",
    "            rows.append({\n",
    "                \"sentence\": text,\n",
    "                \"sentence_raw\":raw_text,\n",
    "                \"aspect\": aspect_clean,\n",
    "                \"polarity\": pol,\n",
    "                \"window\": window,\n",
    "                \"input_full\": input_full,\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ed9b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "FASTTEXT_BIN = \"cc.en.300.bin\"\n",
    "\n",
    "def load_fasttext_model():\n",
    "    \"\"\"\n",
    "    Load (or download) pretrained FastText English model.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(FASTTEXT_BIN):\n",
    "        print(\"Downloading FastText English model (cc.en.300.bin)...\")\n",
    "        fasttext.util.download_model('en', if_exists='ignore')  # creates cc.en.300.bin\n",
    "    model = fasttext.load_model(FASTTEXT_BIN)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_fasttext_matrix(texts, ft_model):\n",
    "    \"\"\"\n",
    "    texts: Iterable[str] of input strings (we'll use the 'window' column).\n",
    "    Returns: np.array [n_samples, dim]\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    for t in texts:\n",
    "        v = ft_model.get_sentence_vector(t)\n",
    "        vectors.append(v)\n",
    "    return np.vstack(vectors)\n",
    "\n",
    "\n",
    "def train_fasttext_svm(X_train, y_train,X_test=None,y_test=None):\n",
    "    clf = LinearSVC(C=1.0, random_state=RANDOM_STATE)\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_train,y_train)\n",
    "    \n",
    "    print(\"\\n===== FastText + SVM =====\")\n",
    "    print(f\"Training Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_pred = clf.predict(X_test)\n",
    "        test_acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    return clf, acc\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10b42408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test=None, y_test=None):\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    acc = model.score(X_train,y_train)\n",
    "    print(f\"Training Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "        \n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_results(results_list):\n",
    "    df = pd.DataFrame(results_list)\n",
    "    print(\"\\n=== SUMMARY (classical models) ===\")\n",
    "    print(df.sort_values(\"accuracy\", ascending=False))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "062105c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "def build_vectorizer():\n",
    "    \"\"\"\n",
    "    Build a FeatureUnion of:\n",
    "      - word-level TF-IDF (1–2 grams)\n",
    "      - char-level TF-IDF (3–5 char grams)\n",
    "    Input: one string per sample (we'll feed \"window\" column).\n",
    "    \"\"\"\n",
    "    word_tfidf = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=10000,\n",
    "        sublinear_tf=True,\n",
    "        analyzer=\"word\"\n",
    "    )\n",
    "\n",
    "    char_tfidf = TfidfVectorizer(\n",
    "        ngram_range=(3, 5),\n",
    "        max_features=20000,\n",
    "        sublinear_tf=True,\n",
    "        analyzer=\"char\"\n",
    "    )\n",
    "\n",
    "    vectorizer = FeatureUnion([\n",
    "        (\"word\", word_tfidf),\n",
    "        (\"char\", char_tfidf),\n",
    "    ])\n",
    "\n",
    "    return vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5580cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "def get_base_models():\n",
    "    \"\"\"\n",
    "    Return individual base models.\n",
    "    \"\"\"\n",
    "    logreg = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        C=1.0,\n",
    "        class_weight=None,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    svm = LinearSVC(\n",
    "        C=1.0\n",
    "    )\n",
    "\n",
    "    knn = KNeighborsClassifier(\n",
    "        n_neighbors=5\n",
    "    )\n",
    "\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=15,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        \"logreg\": logreg,\n",
    "        \"svm\": svm,\n",
    "        \"knn\": knn,\n",
    "        \"dt\": dt,\n",
    "    }\n",
    "    return models\n",
    "\n",
    "\n",
    "def get_ensemble(models_dict):\n",
    "    \"\"\"\n",
    "    Build a soft voting ensemble (where possible).\n",
    "    For LinearSVC (no predict_proba), we use hard voting.\n",
    "    \"\"\"\n",
    "    estimators = [(name, m) for name, m in models_dict.items()]\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=estimators,\n",
    "        voting=\"hard\"   # soft requires predict_proba; LinearSVC doesn't have it\n",
    "    )\n",
    "    return ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eff8b151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading XML data from: C:\\Users\\ahmed\\Downloads\\aspect_extraction_and_classification\\final_dataset.jsonl\n",
      "Total aspect instances: 20678\n",
      "                                            sentence  \\\n",
      "0  this sound track was beautiful! it paints the ...   \n",
      "1  this sound track was beautiful! it paints the ...   \n",
      "2  this sound track was beautiful! it paints the ...   \n",
      "3  this sound track was beautiful! it paints the ...   \n",
      "4  this sound track was beautiful! it paints the ...   \n",
      "\n",
      "                                        sentence_raw       aspect  polarity  \\\n",
      "0  This sound track was beautiful! It paints the ...  sound track  positive   \n",
      "1  This sound track was beautiful! It paints the ...        music  positive   \n",
      "2  This sound track was beautiful! It paints the ...      guitars  positive   \n",
      "3  This sound track was beautiful! It paints the ...   orchestras  positive   \n",
      "4  This sound track was beautiful! It paints the ...  keyboarding  negative   \n",
      "\n",
      "                                              window  \\\n",
      "0      this sound track was beautiful! it paints the   \n",
      "1  people who hate vid. game music! i have played...   \n",
      "2  a fresher step with grate guitars and soulful ...   \n",
      "3  with grate guitars and soulful orchestras. it ...   \n",
      "4  it backs away from crude keyboarding and takes...   \n",
      "\n",
      "                                          input_full  \n",
      "0  sound track [SEP] this sound track was beautif...  \n",
      "1  music [SEP] this sound track was beautiful! it...  \n",
      "2  guitars [SEP] this sound track was beautiful! ...  \n",
      "3  orchestras [SEP] this sound track was beautifu...  \n",
      "4  keyboarding [SEP] this sound track was beautif...  \n",
      "\n",
      "Building TF-IDF (word + char) vectorizer...\n",
      "Fitting TF-IDF on training data...\n",
      "\n",
      "===== logreg =====\n",
      "Training Accuracy: 0.8671\n",
      "Test Accuracy: 0.7142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7022    0.8007    0.7482      1841\n",
      "     neutral     0.5678    0.1390    0.2233       482\n",
      "    positive     0.7363    0.7794    0.7572      1813\n",
      "\n",
      "    accuracy                         0.7142      4136\n",
      "   macro avg     0.6688    0.5730    0.5763      4136\n",
      "weighted avg     0.7015    0.7142    0.6910      4136\n",
      "\n",
      "\n",
      "===== svm =====\n",
      "Training Accuracy: 0.9739\n",
      "Test Accuracy: 0.6973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7108    0.7556    0.7325      1841\n",
      "     neutral     0.4268    0.2780    0.3367       482\n",
      "    positive     0.7287    0.7496    0.7390      1813\n",
      "\n",
      "    accuracy                         0.6973      4136\n",
      "   macro avg     0.6221    0.5944    0.6027      4136\n",
      "weighted avg     0.6855    0.6973    0.6892      4136\n",
      "\n",
      "\n",
      "===== knn =====\n",
      "Training Accuracy: 0.7578\n",
      "Test Accuracy: 0.6219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.5926    0.7876    0.6763      1841\n",
      "     neutral     0.3516    0.1328    0.1928       482\n",
      "    positive     0.7021    0.5836    0.6373      1813\n",
      "\n",
      "    accuracy                         0.6219      4136\n",
      "   macro avg     0.5488    0.5013    0.5021      4136\n",
      "weighted avg     0.6125    0.6219    0.6029      4136\n",
      "\n",
      "\n",
      "===== dt =====\n",
      "Training Accuracy: 0.6281\n",
      "Test Accuracy: 0.5571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.5364    0.7208    0.6151      1841\n",
      "     neutral     0.1613    0.0104    0.0195       482\n",
      "    positive     0.5960    0.5361    0.5645      1813\n",
      "\n",
      "    accuracy                         0.5571      4136\n",
      "   macro avg     0.4312    0.4224    0.3997      4136\n",
      "weighted avg     0.5188    0.5571    0.5235      4136\n",
      "\n",
      "\n",
      "===== ensemble =====\n",
      "Training Accuracy: 0.8513\n",
      "Test Accuracy: 0.6833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6318    0.8593    0.7282      1841\n",
      "     neutral     0.6061    0.1245    0.2065       482\n",
      "    positive     0.7723    0.6531    0.7077      1813\n",
      "\n",
      "    accuracy                         0.6833      4136\n",
      "   macro avg     0.6701    0.5456    0.5475      4136\n",
      "weighted avg     0.6904    0.6833    0.6584      4136\n",
      "\n",
      "\n",
      "=== SUMMARY (classical models) ===\n",
      "      model  accuracy\n",
      "1       svm  0.973885\n",
      "0    logreg  0.867066\n",
      "4  ensemble  0.851288\n",
      "2       knn  0.757768\n",
      "3        dt  0.628098\n",
      "\n",
      "Loading FastText model...\n",
      "Building FastText sentence vectors for train and test...\n",
      "\n",
      "===== FastText + SVM =====\n",
      "Training Accuracy: 0.7021\n",
      "Test Accuracy: 0.7065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6850    0.8267    0.7492      1841\n",
      "     neutral     0.7500    0.0373    0.0711       482\n",
      "    positive     0.7312    0.7623    0.7464      1813\n",
      "\n",
      "    accuracy                         0.7065      4136\n",
      "   macro avg     0.7221    0.5421    0.5223      4136\n",
      "weighted avg     0.7128    0.7065    0.6690      4136\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "      model  accuracy\n",
      "1       svm  0.973885\n",
      "0    logreg  0.867066\n",
      "4  ensemble  0.851288\n",
      "2       knn  0.757768\n",
      "3        dt  0.628098\n",
      "\n",
      "FastText + SVM accuracy: 0.7021\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jsonl_loader import load_jsonl_aspects\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"Loading XML data from: {DATA_PATH}\")\n",
    "#parsed_xml = load_semeval_xml(DATA_PATH)\n",
    "parsed_jsonl = load_jsonl_aspects(DATA_PATH)\n",
    "parsed = parsed_jsonl \n",
    "\n",
    "df = build_apc_dataset_with_windows(parsed, window_size=WINDOW_SIZE)\n",
    "df = df[df[\"polarity\"]!=\"conflict\"].reset_index(drop=True)\n",
    "# Optionally: drop 'conflict' if it’s too rare and hurting training\n",
    "# df = df[df[\"polarity\"] != \"conflict\"].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total aspect instances: {len(df)}\")\n",
    "print(df.head())\n",
    "\n",
    "# Use aspect-centered window with <ASP> tags as main input\n",
    "texts = df[\"window\"].values\n",
    "texts_raw = df[\"sentence_raw\"].values\n",
    "labels = df[\"polarity\"].values\n",
    "\n",
    "# Stratified split for fair evaluation\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=labels\n",
    ")\n",
    "X_train_raw, X_test_raw, _, _ = train_test_split(\n",
    "    texts_raw, labels,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=labels\n",
    ")\n",
    "# ====================================\n",
    "# 2. Classical ML: TF-IDF (word+char)\n",
    "# ====================================\n",
    "print(\"\\nBuilding TF-IDF (word + char) vectorizer...\")\n",
    "vectorizer = build_vectorizer()\n",
    "\n",
    "print(\"Fitting TF-IDF on training data...\")\n",
    "X_train_vec = vectorizer.fit_transform(X_train_texts)\n",
    "X_test_vec = vectorizer.transform(X_test_texts)\n",
    "\n",
    "# 2.1 Train individual models\n",
    "base_models = get_base_models()\n",
    "results = []\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    res = evaluate_model(name, model, X_train_vec, y_train, X_test_vec, y_test)\n",
    "    results.append(res)\n",
    "\n",
    "# 2.2 Train ensemble\n",
    "ensemble = get_ensemble(base_models)\n",
    "res_ens = evaluate_model(\"ensemble\", ensemble, X_train_vec, y_train, X_test_vec, y_test)\n",
    "results.append(res_ens)\n",
    "\n",
    "summary_df = summarize_results(results)\n",
    "\n",
    "# ====================================\n",
    "# 3. FastText + SVM comparison\n",
    "# ====================================\n",
    "print(\"\\nLoading FastText model...\")\n",
    "ft_model = load_fasttext_model()\n",
    "\n",
    "print(\"Building FastText sentence vectors for train and test...\")\n",
    "X_train_ft = build_fasttext_matrix(X_train_raw, ft_model)\n",
    "X_test_ft = build_fasttext_matrix(X_test_raw, ft_model)\n",
    "\n",
    "ft_clf, ft_acc = train_fasttext_svm(X_train_ft, y_train, X_test_ft, y_test)\n",
    "\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(summary_df.sort_values(\"accuracy\", ascending=False))\n",
    "print(f\"\\nFastText + SVM accuracy: {ft_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6089a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "def evaluate_kfold(model, X, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(model, X, y, cv=skf, scoring=\"accuracy\")\n",
    "    return scores.mean(), scores.std()\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. RUN K-FOLD EVALUATION FOR ALL CLASSICAL MODELS\n",
    "# --------------------------------------------------------\n",
    "def evaluate_all_models_kfold(X_vec, y, folds=5):\n",
    "    base_models = get_base_models()\n",
    "    results = {}\n",
    "\n",
    "    for name, model in base_models.items():\n",
    "        mean_acc, std_acc = evaluate_kfold(model, X_vec, y, folds=folds)\n",
    "        print(f\"{name}: {mean_acc:.4f} (+/- {std_acc:.4f})\")\n",
    "        results[name] = (mean_acc, std_acc)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. FASTTEXT + SVM K-FOLD EVALUATION\n",
    "# --------------------------------------------------------\n",
    "def evaluate_fasttext_kfold(texts_raw, labels, ft_model, folds=5):\n",
    "    X_ft = build_fasttext_matrix(texts_raw, ft_model)\n",
    "    svm = LinearSVC(C=1.0, random_state=RANDOM_STATE)\n",
    "\n",
    "    mean_acc, std_acc = evaluate_kfold(svm, X_ft, labels, folds=folds)\n",
    "    print(f\"FastText + SVM: {mean_acc:.4f} (+/- {std_acc:.4f})\")\n",
    "\n",
    "    return mean_acc, std_acc, X_ft\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4. HYPERPARAMETER SEARCH FOR THE SELECTED MODEL (SVM EXAMPLE)\n",
    "# ---------------------------------------------------------------\n",
    "def svm_hyperparameter_search(X, y, C_values=[0.01, 0.1, 1, 2, 5], folds=5):\n",
    "    best_C = None\n",
    "    best_acc = -1\n",
    "\n",
    "    print(\"\\n=== SVM Hyperparameter Search ===\")\n",
    "    for C in C_values:\n",
    "        model = LinearSVC(C=C, random_state=RANDOM_STATE)\n",
    "        mean_acc, std_acc = evaluate_kfold(model, X, y, folds=folds)\n",
    "        print(f\"C={C}: {mean_acc:.4f} (+/- {std_acc:.4f})\")\n",
    "\n",
    "        if mean_acc > best_acc:\n",
    "            best_acc = mean_acc\n",
    "            best_C = C\n",
    "\n",
    "    print(f\"\\nBest C = {best_C} (accuracy = {best_acc:.4f})\")\n",
    "    return best_C\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5. TRAIN FINAL MODEL ON FULL TRAINING SET\n",
    "# ---------------------------------------------------------------\n",
    "def train_final_svm(X, y, C):\n",
    "    model = LinearSVC(C=C, random_state=RANDOM_STATE)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 6. EVALUATE FINAL MODEL ON SEPARATE TEST SET\n",
    "# ---------------------------------------------------------------\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def evaluate_final_model(model, X_test, y_test):\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"\\n=== FINAL TEST ACCURACY ===\\nAccuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, preds, digits=4))\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d1ac216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "=== STRATIFIED K-FOLD (TRAIN SET ONLY)\n",
      "======================\n",
      "\n",
      "Running K-Fold for: logreg\n",
      "logreg: mean=0.7020  std=0.0075\n",
      "\n",
      "Running K-Fold for: svm\n",
      "svm: mean=0.6885  std=0.0045\n",
      "\n",
      "Running K-Fold for: knn\n",
      "knn: mean=0.6234  std=0.0034\n",
      "\n",
      "Running K-Fold for: dt\n",
      "dt: mean=0.5617  std=0.0053\n",
      "\n",
      "Building FastText vectors for K-Fold…\n",
      "FastText matrix shape: (16542, 300)\n",
      "\n",
      "Running K-Fold for: fasttext_svm\n",
      "fasttext_svm: mean=0.6820  std=0.0034\n",
      "\n",
      "=== BEST MODEL SELECTED: logreg (0.7020) ===\n",
      "\n",
      "======================\n",
      "=== FINAL TEST EVALUATION ===\n",
      "======================\n",
      "logreg Test Accuracy: 0.7142166344294004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.80      0.75      1841\n",
      "     neutral       0.57      0.14      0.22       482\n",
      "    positive       0.74      0.78      0.76      1813\n",
      "\n",
      "    accuracy                           0.71      4136\n",
      "   macro avg       0.67      0.57      0.58      4136\n",
      "weighted avg       0.70      0.71      0.69      4136\n",
      "\n",
      "\n",
      "CV RESULTS:\n",
      "logreg: mean=0.7020, std=0.0075\n",
      "svm: mean=0.6885, std=0.0045\n",
      "knn: mean=0.6234, std=0.0034\n",
      "dt: mean=0.5617, std=0.0053\n",
      "fasttext_svm: mean=0.6820, std=0.0034\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# CELL 10 — Stratified K-Fold Model Selection + Final Evaluation\n",
    "# =============================================================\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# PART 1 — Generic K-Fold evaluator (works with sparse or dense)\n",
    "# =============================================================\n",
    "\n",
    "def evaluate_kfold_estimator(name, estimator, X, y, folds=5):\n",
    "    print(f\"\\nRunning K-Fold for: {name}\")\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=folds,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    y = np.array(y)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "\n",
    "        # Sparse matrix slicing works directly:\n",
    "        X_tr = X[train_idx]\n",
    "        X_val = X[val_idx]\n",
    "\n",
    "        y_tr = y[train_idx]\n",
    "        y_val = y[val_idx]\n",
    "\n",
    "        est = clone(estimator)\n",
    "        est.fit(X_tr, y_tr)\n",
    "        preds = est.predict(X_val)\n",
    "\n",
    "        fold_acc = accuracy_score(y_val, preds)\n",
    "        scores.append(fold_acc)\n",
    "\n",
    "    mean_acc = float(np.mean(scores))\n",
    "    std_acc  = float(np.std(scores))\n",
    "\n",
    "    print(f\"{name}: mean={mean_acc:.4f}  std={std_acc:.4f}\")\n",
    "    return mean_acc, std_acc\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# PART 2 — K-Fold for TF-IDF models\n",
    "# =============================================================\n",
    "\n",
    "def evaluate_all_models_kfold(X_vec, y, folds=5):\n",
    "    base_models = get_base_models()   # your function\n",
    "    results = {}\n",
    "\n",
    "    for name, model in base_models.items():\n",
    "        mean_acc, std_acc = evaluate_kfold_estimator(\n",
    "            name, model, X_vec, y, folds=folds\n",
    "        )\n",
    "        results[name] = (mean_acc, std_acc)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# PART 3 — FastText per-ASPECT VECTORS (critical fix)\n",
    "# =============================================================\n",
    "\n",
    "def evaluate_fasttext_kfold(text_windows_train, y_train, ft_model, folds=5):\n",
    "    \"\"\"\n",
    "    IMPORTANT:\n",
    "    We embed *WINDOWS* (or sentence_raw), NOT unique sentences.\n",
    "    Each row corresponds to ONE ASPECT INSTANCE.\n",
    "    \"\"\"\n",
    "    print(\"\\nBuilding FastText vectors for K-Fold…\")\n",
    "    X_ft = build_fasttext_matrix(text_windows_train, ft_model)\n",
    "    print(\"FastText matrix shape:\", X_ft.shape)\n",
    "\n",
    "    svm = LinearSVC(C=1.0, random_state=RANDOM_STATE)\n",
    "\n",
    "    mean_acc, std_acc = evaluate_kfold_estimator(\n",
    "        \"fasttext_svm\", svm, X_ft, y_train, folds=folds\n",
    "    )\n",
    "\n",
    "    return mean_acc, std_acc, X_ft\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# PART 4 — RUN K-FOLD ON TRAIN SET ONLY\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"=== STRATIFIED K-FOLD (TRAIN SET ONLY)\")\n",
    "print(\"======================\")\n",
    "\n",
    "# TF-IDF models\n",
    "cv_results = evaluate_all_models_kfold(X_train_vec, y_train, folds=5)\n",
    "\n",
    "# FastText ASPECT-LEVEL vectors\n",
    "ft_cv_mean, ft_cv_std, X_train_ft = evaluate_fasttext_kfold(\n",
    "    X_train_texts,  # THE ASPECT WINDOW TEXTS (matches df rows)\n",
    "    y_train,\n",
    "    ft_model,\n",
    "    folds=5\n",
    ")\n",
    "\n",
    "cv_results[\"fasttext_svm\"] = (ft_cv_mean, ft_cv_std)\n",
    "\n",
    "# Determine best model by mean accuracy\n",
    "best_model_name = max(cv_results, key=lambda k: cv_results[k][0])\n",
    "best_model_cv   = cv_results[best_model_name][0]\n",
    "\n",
    "print(f\"\\n=== BEST MODEL SELECTED: {best_model_name} ({best_model_cv:.4f}) ===\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# PART 5 — FINAL RETRAIN ON FULL TRAINING SET + TEST EVAL\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"=== FINAL TEST EVALUATION ===\")\n",
    "print(\"======================\")\n",
    "\n",
    "if best_model_name == \"fasttext_svm\":\n",
    "    # Build final test vectors\n",
    "    X_test_ft = build_fasttext_matrix(X_test_texts, ft_model)\n",
    "\n",
    "    clf = LinearSVC(C=1.0, random_state=RANDOM_STATE)\n",
    "    clf.fit(X_train_ft, y_train)\n",
    "    preds = clf.predict(X_test_ft)\n",
    "\n",
    "    print(\"FastText+SVM Test Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "else:\n",
    "    # Classical models (TF-IDF)\n",
    "    base_models = get_base_models()\n",
    "    clf = base_models[best_model_name]\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    preds = clf.predict(X_test_vec)\n",
    "\n",
    "    print(f\"{best_model_name} Test Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "\n",
    "# Show summary table\n",
    "print(\"\\nCV RESULTS:\")\n",
    "for k, v in cv_results.items():\n",
    "    print(f\"{k}: mean={v[0]:.4f}, std={v[1]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
